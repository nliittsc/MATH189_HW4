
The following is an Rnotebook collection of the code used in Homework 4. It was primarily compiled by Nathan Liittschwager, but every group member contributed to its creation
What follows is primarily a succinct version of the code used for homework 4. We credit the various stack exchange forums for providing partial solutions to many problems.


In order to remove any error of the fitting, we take the average of the given gains at each density. We produce the following data. We also attached a log transformation of the log-gain. 

```{r}
summary(gauge2)
gauge$expdensity <- exp(gauge$density)
gauge$expgain <- exp(gauge$gain)

```

We now fit a polynormial model
```{r}
gauge$loggain <- log(gauge$gain)
log.model <- lm(loggain ~ density, gauge)
summary(log.model)
qqnorm(log.model$residuals)
qqline(log.model$residuals)
```

We now fit a 2nd order polynomial model to the data
```{r}
library(ggplot2)
ggplot(gauge, aes(x = density, y = loggain)) +
  geom_point(alpha = 0.8, col = "blue") +
  stat_smooth(method = "lm", formula = y ~ x, color = "red", level = 0.95, se= TRUE, show.legend = TRUE) +
  ggtitle(" Regression of Density onto log transformed Gain") +
  theme_bw() +
  theme(plot.title=element_text(size=16,face="bold"),
         axis.text=element_text(size=18),
         axis.title=element_text(size=20,face="bold"))
```



We can now fit the model and accompaning prediction band onto the data set
```{r}
library(investr)
plotFit(log.model, interval = "prediction", xlab = "Tansformed Gain", ylab = "Density", col.pred = "pink", pch = 19, shade = T, main = "Least Squares Line with 95% Prediction Band", cex.lab = 1.5)
```





We now take a look at the residuals to ask if there is a problem with the fit. We plot the residuals, which look approximately random
```{r}
plot(log.model$residuals, pch = 19, col = "blue", ylab = "Residuals", main = "Log-Transformed Model Residuals", cex.lab = 1.5)
abline(0,0, col = "red")
```

We now spend some time to identify if the residuals are approximately normally distributed
```{r}
library(nortest)
qqnorm(log.model$residuals, main = "QQplot of Residuals from Log-Transformed Model", col = "blue", pch = 19, cex.lab = 1.6)
qqline(log.model$residuals)
shapiro.test(poly.model$residuals)

```


We now predict using the inverted prediction intervals of the log-transformed model. 
```{r}
calibrate(log.model, y0 = log(38.6), interval = "inversion")
```
The prediction here is pretty good, almost dead on.

```{r}
calibrate(log.model, y0 = log(130.6), interval = "inversion")
```


```{r}
calibrate(log.model, y0 = log(427.6), interval = "inversion")
```
The prediction here is not as good, returning a negative value, when the actual density is 0.001



NOW
To compare models, we fit a fourth order polynomial to the gauge2 data, where the average of the gain is taken and fit to each density.


```{r}
poly.model <- lm(density ~ poly(gain, 3), gauge2)
summary(poly.model)
```


Note that the 4th order polynomial fits remarkably well, perhaps too well.
```{r}
ggplot(gauge2, aes(x = gain, y = density)) +
  geom_point(alpha = 0.8, col = "black") +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), color = "red") +
  ggtitle("3rd Order Polynomial Regression of Density onto Gain") +
  theme_bw() +
  theme(plot.title=element_text(size=16,face="bold"),
         axis.text=element_text(size=18),
         axis.title=element_text(size=20,face="bold"))
```


There is apparent random scatter.
```{r}
plot(poly.model$residuals, pch = 19, col = "blue", ylab = "Residuals", cex.lab = 1.6, main = "Polynomial Model Residuals")
abline(0,0, col = "red")
qqnorm(poly.model$residuals, main = "Polynomial Model QQPlot", col = "blue", pch = 19, cex.lab = 1.6)
qqline(poly.model$residuals)
shapiro.test(poly.model$residuals) #test didnt reject, p = 0.80, but probably low power
```

note that the prediction is remarkably good, better than the log-model. 
```{r}
fakedata <- data.frame(gain = c(38.6, 130.6, 427.7))
predict(poly.model, newdata = fakedata,  interval = "prediction")
```

We now perform the cross-validation aspect and compare which of our models, the polynomial or the log-transformation model perform better. First we do so with the log model.
```{r}
gaugeomit1 <- gauge[-(21:30),]
gaugeomit2 <- gauge[-(81:90),]
omit.log.model1 <- lm(loggain ~ density, gaugeomit1)
omit.log.model2 <- lm(loggain ~ density, gaugeomit2)
calibrate(omit.log.model1, y0 = log(38.6), interval = "inversion")
calibrate(omit.log.model2, y0 = log(426.7), interval = "inversion")
```
We see that the model predicts the .508 density still pretty well, but suffers when trying to predict the 0.001 density after cross validation. We now compare to the polynomial model

```{r}
gauge2omit1 <- gauge2[-3,]
gauge2omit2 <- gauge2[-9,]
omit.poly.model1 <- lm(density ~ poly(gain, 3), gauge2omit1)
omit.poly.model2 <- lm(density~ poly(gain, 3), gauge2omit2)
predict(omit.poly.model1, newdata = data.frame(gain = c(38.6 )), interval = "prediction")
predict(omit.poly.model2, newdata = data.frame(gain = c(  426.7)), interval = "prediction")
```

We can see that the polynomial model performs pretty well with the first cross-validation, but not as well as the log-model
And it performs EXTREMELY badly with the second cross-validation. It appears the log-transformation model is better.

ADDITIONAL:
Regression on time series data. We make a ggplot on time series data

```{r}
library(ggfortify)
tempagg <- aggregate(SURF_TEMP_C ~ YEAR, tempdata, mean)
temp.model <- lm(SURF_TEMP_C ~ poly(YEAR,2), tempagg)
ggplot(tempagg, aes(x = YEAR, y = SURF_TEMP_C))+
  xlim(1916, 2028) +
  xlab("Years")+
  ylab("Surface Temp (Celsius)") +
  ggtitle("Prediction Interval on Sea Surface Temperature")+
  geom_hline(yintercept = mean(tempagg$SURF_TEMP_C), linetype = "dashed", color = "red")+
  geom_line(colour = "darkblue")+
  stat_smooth(method = "lm", formula = y~poly(x, 2), fullrange = TRUE, colour = "coral2", fill = "pink")+
  theme_gray(base_size = 16)
```

```{r}
plot(temp.model$residuals, ylab = "Residuals", main = "Residuals of Temperature Model", cex.lab = 1.6, pch=19, col = "blue")
abline(0,0, col = "red")
```

```{r}
qqnorm(temp.model$residuals, main = "QQplot of Residuals from Temperature Model", col = "blue", pch = 19, cex.lab = 1.6)
qqline(temp.model$residuals)
shapiro.test(temp.model$residuals) #0.053
```

```{r}
dataz <- data.frame(YEAR = c(2020, 2024, 2028))
predict(temp.model, newdata = dataz, interval = "prediction")
```

